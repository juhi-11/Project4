{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNPZXHSeIlXH/tkG0X1m1GR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juhi-11/Project4/blob/main/SentimentAnalysis_InfoRetrieval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# Load your dataset\n",
        "data = pd.read_csv('/content/uci-news-aggregator.csv')\n",
        "\n",
        "# data.columns = ['source', 'author', 'title', 'description', 'url', 'published_at', 'sentiment', 'type']\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gM5gMSoSBufE",
        "outputId": "49fc80c4-e1d1-4e9b-cdbf-99bba01eab16"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3ysIZcECJP1",
        "outputId": "61b43145-7a9d-4b6f-90dd-da0e320a3937"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['ID', 'TITLE', 'URL', 'PUBLISHER', 'CATEGORY', 'STORY', 'HOSTNAME',\n",
            "       'TIMESTAMP'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = re.sub(r'\\W', ' ', text)  # Remove non-word characters\n",
        "    text = re.sub(r'\\s+', ' ', text)  # Remove extra spaces\n",
        "    text = text.lower()  # Convert to lowercase\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    filtered_words = [word for word in tokens if word not in stop_words]\n",
        "    return ' '.join(filtered_words)\n",
        "\n",
        "# Apply preprocessing to the TITLE column\n",
        "data['cleaned_text'] = data['TITLE'].apply(preprocess_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ceYnNnOCsjW",
        "outputId": "77a5afe5-15fa-47e3-dc51-af0ddc9758c5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn nltk textblob"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-HYeCNadDQff",
        "outputId": "c47978c0-4983-4a97-9479-c962c6718d86"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.10/dist-packages (0.17.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "def get_sentiment(text):\n",
        "    analysis = TextBlob(text)\n",
        "    # Classify sentiment as Positive, Negative, or Neutral\n",
        "    if analysis.sentiment.polarity > 0:\n",
        "        return 'POSITIVE'\n",
        "    elif analysis.sentiment.polarity < 0:\n",
        "        return 'NEGATIVE'\n",
        "    else:\n",
        "        return 'NEUTRAL'\n",
        "\n",
        "# Apply sentiment analysis on the TITLE column\n",
        "data['sentiment'] = data['TITLE'].apply(get_sentiment)\n"
      ],
      "metadata": {
        "id": "xDjIB_86KXmz"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use TF-IDF to vectorize the cleaned TITLE data\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(data['cleaned_text'])"
      ],
      "metadata": {
        "id": "8r1PRt4yKahi"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def search_query(query, sentiment_filter):\n",
        "    # Preprocess the query\n",
        "    query = preprocess_text(query)\n",
        "\n",
        "    # Transform the query to a vector\n",
        "    query_vec = tfidf_vectorizer.transform([query])\n",
        "\n",
        "    # Compute cosine similarity between the query and the documents\n",
        "    similarities = cosine_similarity(query_vec, tfidf_matrix).flatten()\n",
        "\n",
        "    # Filter by sentiment\n",
        "    filtered_data = data[data['sentiment'] == sentiment_filter]\n",
        "    filtered_similarities = similarities[filtered_data.index]\n",
        "\n",
        "    # Get top 5 most similar documents\n",
        "    top_indices = filtered_similarities.argsort()[-5:][::-1]\n",
        "    results = filtered_data.iloc[top_indices]\n",
        "\n",
        "    return results[['TITLE', 'PUBLISHER', 'sentiment', 'URL']]\n",
        "\n",
        "# Example usage\n",
        "query = \"tech innovations\"\n",
        "sentiment_filter = \"POSITIVE\"  # Can be 'POSITIVE', 'NEGATIVE', or 'NEUTRAL'\n",
        "results = search_query(query, sentiment_filter)\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1Xg7dtILmxg",
        "outputId": "4473ff2f-b7c1-46be-de4a-4e0eebcc488b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                    TITLE  \\\n",
            "413835  For VMware, keep friendly tech close (and enem...   \n",
            "136807  Fearing Tech: Americans report fear and love f...   \n",
            "125156       Google Glass: the New Symbol of Tech Disgust   \n",
            "335991                        The Great Tech Lull of 2014   \n",
            "282638  TECH STOCKS: Intel, OpenTable Lead Tech Sector...   \n",
            "\n",
            "                           PUBLISHER sentiment  \\\n",
            "413835                       Fortune  POSITIVE   \n",
            "136807                    Tech Times  POSITIVE   \n",
            "125156                  Equities.com  POSITIVE   \n",
            "335991                  DailyFinance  POSITIVE   \n",
            "282638  Capital.gr \\(press release\\)  POSITIVE   \n",
            "\n",
            "                                                      URL  \n",
            "413835  http://fortune.com/2014/08/25/vmware-vmworld-2...  \n",
            "136807  http://www.techtimes.com/articles/5736/2014041...  \n",
            "125156  http://www.equities.com/editors-desk/stocks/te...  \n",
            "335991  http://www.dailyfinance.com/2014/06/29/the-gre...  \n",
            "282638     http://english.capital.gr/News.asp\\?id=2040606  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data for evaluation (if you have true sentiment labels)\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['cleaned_text'], data['sentiment'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Predict sentiments for the test data\n",
        "y_pred = [get_sentiment(text) for text in X_test]\n",
        "\n",
        "# Generate a classification report\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWlOE0-3Lr-X",
        "outputId": "d33b0f14-6672-4669-f62e-bd2858a9b751"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    NEGATIVE       0.93      0.90      0.92     11475\n",
            "     NEUTRAL       0.95      0.98      0.97     49661\n",
            "    POSITIVE       0.95      0.92      0.93     23348\n",
            "\n",
            "    accuracy                           0.95     84484\n",
            "   macro avg       0.95      0.93      0.94     84484\n",
            "weighted avg       0.95      0.95      0.95     84484\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FMxQmY2gLyLQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}